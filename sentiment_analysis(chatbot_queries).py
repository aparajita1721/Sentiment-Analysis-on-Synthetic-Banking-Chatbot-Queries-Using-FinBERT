# -*- coding: utf-8 -*-
"""sentiment_analysis(chatbot queries).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sq_vHEdBE5t1XCo3xuOEOK4aNVWNOjwi
"""

!pip install datasets transformers wordcloud

# Import libraries
from datasets import load_dataset
import pandas as pd
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from huggingface_hub import hf_hub_download
from sklearn.metrics import classification_report, accuracy_score
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
import random

!pip install -U datasets

from datasets import load_dataset
dataset = load_dataset("takala/financial_phrasebank", "sentences_75agree", split="train")
df = dataset.to_pandas()
df.head()

# Load FinBERT model for sentiment analysis
model_name = "yiyanghkust/finbert-tone"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Create a sentiment analysis pipeline
finbert = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# Run prediction on the first 10 sentences as a test
sample_sentences = df['sentence'].head(10).tolist()
predictions = finbert(sample_sentences)

# Show predictions
for i in range(10):
    print(f"Sentence: {sample_sentences[i]}")
    print(f"Predicted Sentiment: {predictions[i]['label']} (Score: {predictions[i]['score']:.2f})\n")

# Extract all sentences
sentences = df['sentence'].tolist()

# Run predictions
predictions = finbert(sentences)

# Add predictions to the DataFrame
df['predicted'] = [p['label'].upper() for p in predictions]

# Standardize true labels to match predicted format
label_map = {0: "NEGATIVE", 1: "NEUTRAL", 2: "POSITIVE"}# label mapping
df['label'] = df['label'].map(label_map)

print("Accuracy:", accuracy_score(df['label'], df['predicted']))
print("\nClassification Report:\n")
print(classification_report(df['label'], df['predicted']))

# Base intent templates
intents = {
    "Activate Card": [
        "I need to activate my {card_type}.",
        "How do I activate my {card_type} on {platform}?",
        "Can you help me activate a {card_type}?",
        "I'd like to activate my new {card_type}.",
        "Where can I activate a {card_type}?"
    ],
    "Check Balance": [
        "What's my {account_type} balance?",
        "Show me how much I have in {account_type}.",
        "Can I check my balance for {account_type}?",
        "I'd like to know my current balance.",
        "Tell me the balance in my {account_type}."
    ],
    "Report Lost Card": [
        "I lost my {card_type}, help!",
        "My {card_type} is missing. What should I do?",
        "Can you block my {card_type}?",
        "I've misplaced my {card_type}.",
        "I want to report a lost {card_type}."
    ],
    "Loan Inquiry": [
        "Tell me about your {loan_type} options.",
        "How do I apply for a {loan_type}?",
        "I need a {loan_type}, what are the steps?",
        "What's the interest rate for {loan_type}s?",
        "Am I eligible for a {loan_type}?"
    ],
    "Change Address": [
        "I moved. How can I update my address?",
        "I need to change my address.",
        "How do I update my mailing address?",
        "Can I change the address linked to my account?",
        "Update my address, please."
    ],
    "Complaint": [
        "Why is your service so slow?",
        "Iâ€™ve been charged twice, this is unacceptable.",
        "The app keeps crashing. I'm really frustrated.",
        "This is the worst banking experience ever.",
        "Nobody helped me with my issue last time.",
        "I want to file a complaint. This is ridiculous.",
        "Why can't I talk to a real person?",
        "Every time I try to use the app, it fails.",
        "I've lost money due to your poor support.",
        "My issue has not been resolved in weeks!"
    ]
}

# Dynamic insertions
card_types = ["credit card", "debit card", "Amex card", "Mastercard", "Visa card"]
platforms = ["mobile", "online", "the app"]
account_types = ["checking account", "savings account"]
loan_types = ["personal loan", "student loan", "home loan"]

responses = [
    "Sure, I can help with that.",
    "Please hold while I check.",
    "That request has been completed.",
    "I need more information to proceed.",
    "I'll redirect you to a specialist.",
    "We're sorry to hear that. Let's try to resolve it."
]

# Build dataset
synthetic_data = []

# Generate regular samples (~130)
for _ in range(130):
    intent = random.choice(list(intents.keys() - {"Complaint"}))  # exclude complaint for now
    template = random.choice(intents[intent])

    text = template.format(
        card_type=random.choice(card_types),
        platform=random.choice(platforms),
        account_type=random.choice(account_types),
        loan_type=random.choice(loan_types)
    )

    synthetic_data.append({
        "instruction": text,
        "response": random.choice(responses),
        "intent": intent,
        "sentiment": random.choice(["POSITIVE", "NEUTRAL"])
    })

# Add complaint/negative samples (~20)
for template in random.sample(intents["Complaint"], 10):
    synthetic_data.append({
        "instruction": template,
        "response": random.choice(responses),
        "intent": "Complaint",
        "sentiment": "NEGATIVE"
    })

# Final DataFrame
synthetic_df = pd.DataFrame(synthetic_data)
synthetic_df.head()

synthetic_df = pd.DataFrame(synthetic_data)
# Use existing FinBERT pipeline
synthetic_df['predicted_sentiment'] = [
    result['label'].upper() for result in finbert(synthetic_df['instruction'].tolist())
]

print("Accuracy:", accuracy_score(synthetic_df['sentiment'], synthetic_df['predicted_sentiment']))
print("\nClassification Report:\n")
print(classification_report(synthetic_df['sentiment'], synthetic_df['predicted_sentiment']))

# Plot side-by-side: True vs Predicted Sentiments
fig, axs = plt.subplots(1, 2, figsize=(12, 5))

synthetic_df['sentiment'].value_counts().plot(kind='bar', ax=axs[0], title='True Sentiments')
axs[0].set_xlabel("Sentiment")
axs[0].set_ylabel("Count")
axs[0].grid(axis='y')

synthetic_df['predicted_sentiment'].value_counts().plot(kind='bar', ax=axs[1], title='Predicted Sentiments')
axs[1].set_xlabel("Sentiment")
axs[1].grid(axis='y')

plt.tight_layout()
plt.show()